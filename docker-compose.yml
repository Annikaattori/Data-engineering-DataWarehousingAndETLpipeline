version: "3.9"

services:
  broker:
    image: apache/kafka:latest
    hostname: broker
    container_name: broker
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: "1"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: "1"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@broker:29093"
      KAFKA_LISTENERS: "PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
      

  init-topics:
    image: apache/kafka:latest
    container_name: init-topics
    depends_on:
      - broker
    restart: "no"
    command: >
      bash -lc "
      sleep 8 &&
      /opt/kafka/bin/kafka-topics.sh --create --if-not-exists
      --topic fmi_observations --bootstrap-server broker:29092
      --partitions 1 --replication-factor 1
      "

  producer:
    build:
      context: .
      args:
        REQUIREMENTS_FILE: requirements-worker.txt
    container_name: producer
    depends_on:
      - broker
      - init-topics
    environment:
      KAFKA_BOOTSTRAP_SERVERS: "broker:29092"
      KAFKA_TOPIC: "fmi_observations"
      FMI_API_KEY: "${FMI_API_KEY:-}"
      USE_SAMPLE_DATA: "true"
    volumes:
      - ./keys:/app/keys:ro
    command: ["python", "-m", "src.data_processing.kafka_stream", "produce"]
    stop_signal: SIGINT
    stop_grace_period: 20s
    restart: "no"


  consumer:
    build:
      context: .
      args:
        REQUIREMENTS_FILE: requirements-worker.txt
    container_name: consumer
    depends_on:
      - broker
      - init-topics
    environment:
      KAFKA_BOOTSTRAP_SERVERS: "broker:29092"
      KAFKA_TOPIC: "fmi_observations"
      FMI_API_KEY: "${FMI_API_KEY:-}"
      BIGQUERY_PROJECT: "fmiweatherdatapipeline"
      BIGQUERY_DATASET: "fmi_weather"
      BIGQUERY_DAILY_TABLE: "weather"
      BIGQUERY_API_KEY_PATH: "/app/keys/bigquery/api_key.json"
      GOOGLE_APPLICATION_CREDENTIALS: "/app/keys/bigquery/api_key.json"
    volumes:
      - ./keys:/app/keys:ro
    command: ["python", "-m", "src.data_processing.kafka_stream", "consume", "--max-messages", "5"]
    stop_signal: SIGINT
    stop_grace_period: 20s
    restart: "no"

  streamlit:
    build:
      context: .
      args:
        REQUIREMENTS_FILE: requirements-streamlit.txt
    container_name: streamlit
    depends_on:
      - consumer
    volumes:
      - ./data:/app/data
    environment:
      USE_SAMPLE_DATA: "true"
    ports:
      - "8501:8501"
    command: ["streamlit", "run", "visualization/app.py", "--server.address=0.0.0.0", "--server.port=8501"]
    restart: unless-stopped
